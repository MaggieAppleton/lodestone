import type { TestCase } from "./types";

export const alienAiTest: TestCase = {
	id: 2,
	name: "Alien AI",
	text: "Read Text is All You Need at darkly last night. Got me thinking about AI and personhood Venkat tries to argue that written text is all you need to create 'personhood' – which in his definition means there being a you-I relationship. That feels very much like redefining personhood to me. We don't have the language to talk about our new relationships to language models. They are a new kind of otherness. And we are very bad at recognising and dealing with non-human otherness. We grant rivers and mountains 'personhood' in order to legally protect them from harm. I need to start writing a piece on otherness and language models. I've already started with Alien AIs and Companion Species (although I think it needs a much better name). Thinking about personhood, aliens, companion species, AI, The New Breed, robots as animals, and our ability to deal with otherness. Also, Xenocide by Orson Scott Card. Donna Haraway, Anna Tsing, the movement in anthropology to study forests as if they were people. These themes all come to a head with new AI systems. Andy Clark's AI-ome, like a biome. Systems thinking and seeing ourselves as interconnected networks of beings. I need to write the daemon-fueled version of this, then reverse outline the major themes after. Philosopher Yuk Hui created the concept of Cosmotechnics to describe how technologies are always embedded in the cosmologies of the cultures that create them Cosmologies are 'the unification of the cosmos and the moral through technical activities, whether craft-making or art-making' (Yuk Hui). Conceiving of AI as kin, intertwined in our ecologies, gives them a relationship to plants, animals, and the earth. Many rivers, mountains, and nature reserves have been given legal personhood. In 2014, the Te Urewera park, the ancestral home of the Tuhoe people, became the first natural feature in the country to be recognised as a legal person. In 2018, Mount Taranaki – a 120,000 year-old stratovolcano sacred to the Maori – was awarded the same status. On the Magpie or Mutuhekau Shipu river in Quebec – 'To protect the natural landmark, the Innu Council of Ekuanitshit and the Minganie Regional County Municipality declared the Mutuhekau Shipu a legal person in 2021. It’s part of a global, Indigenous-led campaign echoing the rights of nature movement, which aims to provide concrete protections for the natural landscape. In recent years, many rivers—from New Zealand’s Whanganui to the United States’ Klamath River—have been given personhood. In 2018, Colombia’s Supreme Court granted the Amazon—the world’s largest river—legal rights. Granting rivers legal personhood represents a seismic shift from the bedrock belief in Western society that humans are at the apex of the natural world. But for many Indigenous people, the concept of nature as a sentient equal to humans is nothing new. In Maori culture, for example, ancestors, or tupuna, are embodied in the landscape.' Compelling problem: what’s the best metaphorical framing for “generative AI” systems? Convince the reader metaphors matter and affect how we approach designing and building with these systems. Comparison: the paper metaphor of the web has made us treat all web pages as extensions of white-collar paper-based office work. The kinds of applications we build and interfaces we design mimic typewriters, copyeditors, paper spreadsheets. All our tools are designed for a particular class of knowledge work. Alt vision would be a world of computing designed around the needs of domestic housewives. Metaphors profoundly influence how we understand. Cognitive metaphors structure all abstract thought and reasoning. We're having trouble framing and understanding AI systems. People are currently using the framing of 'aliens' to talk about AI – they're trying to use our limited vocabulary to talk about how we should relate to these new systems. AI insiders refer to language models as 'aliens'. Need evidence of AI heavyweights referencing neural networks as aliens / alien technology. Lay these on thick. 'Alien' is the most common description people are using for AI systems. Which seems like an ill-fitting frame. By alien we're trying to say 'otherness' or 'thing we can be in relationship with.' It doesn't require vast degrees of consciousness for this. We can have a relationship with a river or a hummingbird. We have always struggled to understand non-human beings. We're bad at companion species. At least in our current cultural context we are bad at systems thinking and interconnected relationships. Not all cultures are bad at it. Kate Darlings robots as animals theory. Key points from her book. Summary of the rock-plant-animal-human categories paper. Be as smart as a puppy principle from BERG. We tend to make rock AIs, or really bad human AIs. We should be making plant and animal AIs. What if every time we made an 'AI' system, we consciously decided if it was rock-level, plant-level, or animal-level (you do not try to make human-level AI – it will not work – you will make bad human AIs) Rock level is very basic, no growth or development. E.g. turn unstructured text into structured text. Predictable, doesn't change much over time. Might slowly improve performance but you won't notice it. Plant level is a little more dynamic. Slowly learns and grows in visible ways. Has some small amount of agency, but mostly predictable. Animal level is much more dynamic. Can learn quickly. More unpredictable. You can still control it though. Dogs are still at our beck and call – we decided when they eat and go for walks – but they sometimes do undesirable things like pee on the carpet. Humans level is not an AI level we can make. 'Alien' is the most common description people are using for AI systems. Which seems like an ill-fitting frame. By alien we're trying to say 'otherness' or 'thing we can be in relationship with.' It doesn't require vast degrees of consciousness for this. We can have a relationship with a river or a hummingbird. We have always struggled to understand non-human beings. We're bad at companion species. At least in our current cultural context we are bad at systems thinking and interconnected relationships. Not all cultures are bad at it.",
};
